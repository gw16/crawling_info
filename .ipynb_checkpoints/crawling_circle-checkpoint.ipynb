{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pyrebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_circle():\n",
    "    title_bef =[]\n",
    "    conditions = []\n",
    "    page_num = 1\n",
    "    while(page_num<=5):\n",
    "        url = 'https://www.contestkorea.com/sub/list.php?displayrow=12&Txt_sGn=1&Txt_key=all&Txt_word=&Txt_bcode=030210001&Txt_code1%5B0%5D=30&Txt_code1%5B1%5D=76&Txt_aarea=&Txt_area=&Txt_sortkey=a.int_sort&Txt_sortword=desc&Txt_chocode=&Txt_unicode=&page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        titles = soup.find_all(\"span\", class_ = \"txt\")\n",
    "        titles = list(titles)\n",
    "        condition = soup.find_all(\"span\", class_=\"condition\")\n",
    "        condition = list(condition)\n",
    "        for i in range(len(condition)):\n",
    "            condition[i] = (str(condition[i]).strip('<span class=\"condition\">').strip(\"</span>\"))\n",
    "            if condition[i] != '접수종료':\n",
    "                conditions.append((condition[i]))\n",
    "                titles[i] = (str(titles[i]).strip('<span class=\"txt\">').strip(\"</'\").strip(\" \"))\n",
    "                if '공모전' not in titles[i]:\n",
    "                    title_bef.append(titles[i])\n",
    "                \n",
    "        page_num+=1\n",
    "    return title_bef "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['스타트업과 함께하는 피버팅 해커톤', '2021 다솜이 드림메이커스']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_circle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_circle2():\n",
    "    title_bef =[]\n",
    "    days_bef = []\n",
    "    start_bef = []\n",
    "    end_bef = []\n",
    "    conditions = []\n",
    "    page_num = 1\n",
    "    while(page_num<=5):\n",
    "        url = 'https://www.contestkorea.com/sub/list.php?displayrow=12&Txt_sGn=1&Txt_key=all&Txt_word=&Txt_bcode=030210001&Txt_code1%5B0%5D=30&Txt_code1%5B1%5D=76&Txt_aarea=&Txt_area=&Txt_sortkey=a.int_sort&Txt_sortword=desc&Txt_chocode=&Txt_unicode=&page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        titles = soup.find_all(\"span\", class_ = \"txt\")\n",
    "        titles = list(titles)\n",
    "        condition = soup.find_all(\"span\", class_=\"condition\")\n",
    "        condition = list(condition)\n",
    "#        days = soup.find_all(\"div\", class_=\"date\")\n",
    "        days = soup.select(\".date > div\" )\n",
    "        days = list(days)\n",
    "\n",
    "        for i in range(len(condition)):\n",
    "            days[i] = (str(days[i]).strip('<div>').strip(\">\").strip(\"\\t\"))\n",
    "\n",
    "            \n",
    "            condition[i] = (str(condition[i]).strip('<span class=\"condition\">').strip(\"</span>\"))\n",
    "            if condition[i] != '접수종료':\n",
    "                conditions.append((condition[i]))\n",
    "                titles[i] = (str(titles[i]).strip('<span class=\"txt\">').strip(\"</'\").strip(\" \"))\n",
    "                days[i] = (str(days[i]).strip('<div>').strip('\\n\\t').strip('\\t</'))\n",
    "                \n",
    "                if '공모전' not in titles[i]:\n",
    "                    title_bef.append(titles[i])\n",
    "                    start_day,end_day = days[i].split('~')\n",
    "                    start_bef.append(start_day.replace(\".\", \". \"))\n",
    "                    end_bef.append(end_day.replace(\".\", \". \"))\n",
    "        page_num+=1\n",
    "    return start_bef\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_circle3():\n",
    "    title_bef =[]\n",
    "    days_bef = []\n",
    "    start_bef = []\n",
    "    end_bef = []\n",
    "    conditions = []\n",
    "    inst_bef = []\n",
    "    page_num = 1\n",
    "    while(page_num<=5):\n",
    "        url = 'https://www.contestkorea.com/sub/list.php?displayrow=12&Txt_sGn=1&Txt_key=all&Txt_word=&Txt_bcode=030210001&Txt_code1%5B0%5D=30&Txt_code1%5B1%5D=76&Txt_aarea=&Txt_area=&Txt_sortkey=a.int_sort&Txt_sortword=desc&Txt_chocode=&Txt_unicode=&page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        titles = soup.find_all(\"span\", class_ = \"txt\")\n",
    "        titles = list(titles)\n",
    "        condition = soup.find_all(\"span\", class_=\"condition\")\n",
    "        condition = list(condition)\n",
    "#        days = soup.find_all(\"div\", class_=\"date\")\n",
    "        days = soup.select(\".date > div\" )\n",
    "        days = list(days)\n",
    "        \n",
    "        inst = soup.select(\".host > .icon_1\" )\n",
    "        inst = list(inst)\n",
    "\n",
    "\n",
    "        for i in range(len(condition)):\n",
    "            days[i] = (str(days[i]).strip('<div>').strip(\">\").strip(\"\\t\"))\n",
    "\n",
    "            \n",
    "            condition[i] = (str(condition[i]).strip('<span class=\"condition\">').strip(\"</span>\"))\n",
    "            if condition[i] != '접수종료':\n",
    "                conditions.append((condition[i]))\n",
    "                titles[i] = (str(titles[i]).strip('<span class=\"txt\">').strip(\"</'\").strip(\" \"))\n",
    "                days[i] = (str(days[i]).strip('<div>').strip('\\n\\t').strip('</li>'))\n",
    "                inst[i] = (str(inst[i]).strip('<li class=\"icon_1\"><strong>주최</strong> . ').strip('<div>'))\n",
    "                if '공모전' not in titles[i]:\n",
    "                    title_bef.append(titles[i])\n",
    "                    start_day,end_day = days[i].split('~')\n",
    "                    start_bef.append(start_day.replace(\".\", \". \"))\n",
    "                    end_bef.append(end_day.replace(\".\", \". \"))\n",
    "                    inst_bef.append(inst[i])\n",
    "                    \n",
    "        page_num+=1\n",
    "    return inst_bef\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한국무역협회', '생명보험사회공헌재단, 교보생명']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_circle3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
