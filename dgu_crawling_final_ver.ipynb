{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporated-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "from time import sleep\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "import ssl\n",
    "context=ssl._create_unverified_context()\n",
    "\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aquatic-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrebase\n",
    "import datetime\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vocational-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browser():\n",
    "\n",
    "    url ='https://thinkyou.co.kr/contest/sector.asp'\n",
    "\n",
    "    browser = Chrome('./chromedriver')\n",
    "\n",
    "    delay=3\n",
    "    browser.implicitly_wait(delay)\n",
    "\n",
    "    browser.get(url)\n",
    "\n",
    "    browser.maximize_window()\n",
    "\n",
    "    body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    try :\n",
    "\n",
    "        browser.find_elements_by_xpath('//*[@id=\"searchFrm\"]/div/dl[1]/dd/p[6]/label/span')[0].click()\n",
    "        browser.find_elements_by_xpath('//*[@id=\"searchFrm\"]/div/dl[2]/dd/p[1]/label/span')[0].click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    SCROLL_PAUSE_TIME = 0.5\n",
    "    while True:\n",
    "        last_height = browser.execute_script('return document.documentElement.scrollHeight')\n",
    "\n",
    "        for i in range(3):\n",
    "            body.send_keys(Keys.END)\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = browser.execute_script('return document.documentElement.scrollHeight')\n",
    "        if new_height == last_height:\n",
    "            break;\n",
    "\n",
    "    page = browser.page_source\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling():\n",
    "    soup = browser()\n",
    "\n",
    "    len_day = 20\n",
    "\n",
    "    links_bef = []\n",
    "    titles_bef = []\n",
    "    dday_bef = []\n",
    "    inst_bef = []\n",
    "    start_bef = []\n",
    "    end_bef = []\n",
    "\n",
    "    links_aft = []\n",
    "    titles_aft = []\n",
    "    inst_aft = []\n",
    "\n",
    "    for i in range(len_day):\n",
    "        t = soup.select(' .title > a > dl > dt ')[i].text\n",
    "        fin = soup.select(' .statNew > p ')[i].text\n",
    "\n",
    "\n",
    "        if fin == '마감':\n",
    "            base_url = 'https://thinkyou.co.kr'\n",
    "            titles_aft.append(soup.select(' .title > a > dl > dt ')[i].text)\n",
    "            inst_aft.append(soup.select(' .title > a > dl > dd ')[i].text.split(':')[1][1:])\n",
    "\n",
    "            links_aft.append(base_url + soup.select(' .title > a')[i]['href'][2:])\n",
    "        else:\n",
    "            stand = soup.select(' .statNew')[i].text.split('D')[1]\n",
    "\n",
    "\n",
    "            if stand == '-day':\n",
    "                num = 0\n",
    "                base_url = 'https://thinkyou.co.kr'\n",
    "                titles_bef.append(soup.select(' .title > a > dl > dt ')[i].text)\n",
    "                inst_bef.append(soup.select(' .title > a > dl > dd ')[i].text.split(':')[1][1:])\n",
    "                dday_bef.append(num)\n",
    "                links_bef.append(base_url + soup.select(' .title > a')[i]['href'][2:])\n",
    "                a = i * 2\n",
    "                start_bef.append(soup.select(' .etc')[a].text[:8])\n",
    "                end_bef.append(soup.select(' .etc')[a].text[11:])\n",
    "\n",
    "            else:\n",
    "\n",
    "                base_url = 'https://thinkyou.co.kr'\n",
    "                titles_bef.append(soup.select(' .title > a > dl > dt ')[i].text)\n",
    "                inst_bef.append(soup.select(' .title > a > dl > dd ')[i].text.split(':')[1][1:])\n",
    "                dday_bef.append(soup.select(' .statNew')[i].text.split('-')[1])\n",
    "                links_bef.append(base_url + soup.select(' .title > a')[i]['href'][2:])\n",
    "                a = i * 2\n",
    "                start_bef.append(soup.select(' .etc')[a].text[:8])\n",
    "                end_bef.append(soup.select(' .etc')[a].text[11:])\n",
    "                \n",
    "    print(inst_bef)\n",
    "\n",
    "    tabl_data_bef = {'title': titles_bef, 'notice': start_bef, 'deadline': end_bef, \n",
    "                     'dday': dday_bef, 'sponsor': inst_bef, 'title2': titles_bef, 'link': links_bef}\n",
    "    print(tabl_data_bef)\n",
    "\n",
    "    df_bef = pd.DataFrame(tabl_data_bef, columns=['type', 'qualification', 'title', \n",
    "                                                  'notice', 'deadline', 'dday', 'sponsor', 'title2', 'link'])\n",
    "    \n",
    "    df_bef['type'] = '2 공모전'\n",
    "    \n",
    "    \n",
    "    df_bef['qualification'] = '대학(원)생'\n",
    "\n",
    "\n",
    "    return df_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "applied-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browser2():\n",
    "    url_base = 'https://www.thinkcontest.com/Contest/CateField.html?page=1&c=11'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    res = requests.get(url_base, headers=headers)\n",
    "    soup = BeautifulSoup(res.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "    key = ['과학/공학', '게임/소프트웨어']\n",
    "    links = []\n",
    "    titles = []\n",
    "    dday = []\n",
    "    inst = []\n",
    "    dates = []\n",
    "    k = 1\n",
    "    \n",
    "    while k <= 10:\n",
    "        url = 'https://www.thinkcontest.com/Contest/CateField.html?page=' + str(k) + '&c=11'\n",
    "        base_url = 'https://www.thinkcontest.com/'\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        res = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(res.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "        len_link = len(soup.select(' .txt-left > .contest-title > a'))\n",
    "        for i in range(len_link):\n",
    "            if soup.select(' td > span ')[i].text.replace('\\n', '') == '마감':\n",
    "                break\n",
    "            else:\n",
    "                titles.append(soup.select(' .txt-left > .contest-title > a')[i].text)\n",
    "                links.append(base_url + soup.select('.txt-left > .contest-title > a ')[i]['href'])\n",
    "                dday.append(soup.select(' td > p ')[i].text.split('-')[1])\n",
    "        k=k+1\n",
    "                            \n",
    "    str_date = []\n",
    "    end_date = []\n",
    "    participate = []\n",
    "    for i in range(len(links)):\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        res = requests.get(links[i], headers=headers)\n",
    "        soup = BeautifulSoup(res.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "        html = soup.select(' tr')\n",
    "        text = str(html).replace('\\n', '')\n",
    "        certi = re.compile('참가자격' + '.{200}')\n",
    "        test = certi.findall(text)[0]\n",
    "        partis = []\n",
    "        if '제한없음' in test:\n",
    "            partis.append('대학(원)생')\n",
    "            pass\n",
    "        elif '일반인' in test:\n",
    "            partis.append('대학(원)생')\n",
    "            pass\n",
    "        elif '국내외 석학과 연구진' in test:\n",
    "            partis.append('대학원생')\n",
    "            pass\n",
    "        elif '대학생' in test:\n",
    "            if '대학원생' in test:\n",
    "                partis.append('대학(원)생')\n",
    "                pass\n",
    "            else :\n",
    "                partis.append('대학생')\n",
    "                pass\n",
    "        elif '대학원생' in test:\n",
    "            partis.append('대학원생')\n",
    "        else : \n",
    "            pass\n",
    "            \n",
    "\n",
    "        participant = str(partis).replace('[', '').replace(']', '').replace(\"'\", \"\")\n",
    "        start = re.compile('접수기간' + '.{19}')\n",
    "        strdate = start.findall(text)[0].split('<td>')[1]\n",
    "        end = re.compile('접수기간' + '.{32}')\n",
    "        enddate = end.findall(text)[0].split('~')[1].replace(' ', '')\n",
    "        participate.append(participant)\n",
    "        str_date.append(strdate)\n",
    "        end_date.append(enddate)\n",
    "        inst.append(soup.select(' tbody > tr > td ')[0].text)\n",
    "        \n",
    "        \n",
    "\n",
    "    tabl_data = {'title': titles, 'notice': str_date, 'deadline': end_date, 'dday': dday,\n",
    "                 'qualification': participate, 'sponsor': inst, 'title2': titles,'link': links}\n",
    "\n",
    "    df2 = pd.DataFrame(tabl_data, columns=['type', 'qualification', 'title', \n",
    "                                           'notice', 'deadline', 'dday', 'sponsor', 'title2', 'link'])\n",
    "    df2['type'] = '2 공모전'\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distant-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_allcon():\n",
    "    a_title=[]\n",
    "    a_host=[]\n",
    "    a_terms=[]\n",
    "    a_start_bef=[]\n",
    "    a_end_bef=[]\n",
    "    a_qualification=[]\n",
    "    a_links=[]\n",
    "    a_real_links=[]\n",
    "    url2='https://www.all-con.co.kr/page'\n",
    "    for n in range(1,6):\n",
    "        base_url='https://www.all-con.co.kr/page/uni_activity.php?sc=0&st=2&sstt=&page={}'.format(n)\n",
    "        flag = False\n",
    "        url = base_url.format(n)\n",
    "        webpage = urlopen(url,context=context)\n",
    "        soup = BeautifulSoup(webpage, 'html.parser')\n",
    "        for i in range(1,16):\n",
    "            a_title.append(soup.select('#page_board_contents > div > table > tbody > tr:nth-child('+str(i)+') > td.name > a > p')[0].get_text())\n",
    "            a_host.append(soup.select('#page_board_contents > div > table > tbody > tr:nth-child('+str(i)+') > td:nth-child(3) > p')[0].get_text())\n",
    "            a_terms.append(soup.select('#page_board_contents > div > table > tbody > tr:nth-child('+str(i)+') > td.name > ul > li:nth-child(1) > p.info > span')[0].get_text())\n",
    "            a_qualification.append(soup.select('#page_board_contents > div > table > tbody > tr:nth-child('+str(i)+') > td.name > ul > li:nth-child(2) > p.info')[0].get_text())\n",
    "            a_links.append(soup.select('#page_board_contents > div > table > tbody > tr:nth-child('+str(i)+') > td.name > a')[0].get('href').lstrip('.'))\n",
    "    return a_title, a_host,a_terms, a_qualification,a_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smoking-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allcon_real_link():\n",
    "    a_title, a_host,a_terms ,a_qualification,a_links = parse_allcon()\n",
    "    a_real_links=[]\n",
    "    url2='https://www.all-con.co.kr/page'\n",
    "    for a_link in a_links:\n",
    "        a=url2+a_link\n",
    "        a_real_links.append(a)\n",
    "    \n",
    "    return a_real_links      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allcon_days():\n",
    "    a_title, a_host,a_terms ,a_qualification,a_links = parse_allcon()\n",
    "    a_start_bef=[]\n",
    "    a_end_bef=[]\n",
    "    for a_term in a_terms:\n",
    "        a_start_day,a_end_day=a_term.split(\" ~ \")\n",
    "        a_start_bef.append(a_start_day.replace('.','-'))\n",
    "        a_end_bef.append(a_end_day.replace('.','-'))\n",
    "        \n",
    "    return a_start_bef, a_end_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "weighted-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_allcon():\n",
    "    a_title, a_host,a_terms ,a_qualification,a_links = parse_allcon()\n",
    "    a_real_links = allcon_real_link()\n",
    "    a_start_bef,a_end_bef=allcon_days()\n",
    "    allcon_table_data_bef = {'type':\"4 대외활동\", 'qualification': \"대학(원)생\",'title': a_title, 'notice': a_start_bef,  'deadline': a_end_bef,'dday': 0, 'sponsor':a_host, 'title2': a_title,'link':a_real_links}\n",
    "    df_allcon=pd.DataFrame(allcon_table_data_bef, columns=['type', 'qualification', 'title', 'notice', 'deadline','dday', 'sponsor', 'title2', 'link'])\n",
    "    return df_allcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "second-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_incruit():\n",
    "    inc_title=[]\n",
    "    inc_host=[]\n",
    "    inc_terms=[]\n",
    "    inc_start_bef=[]\n",
    "    inc_end_bef=[]\n",
    "    inc_qualification=[]\n",
    "    inc_links=[]\n",
    "    inc_real_links=[]\n",
    "    base_url='https://gongmo.incruit.com/list/gongmolist.asp?ct=1&category=11'\n",
    "    webpage = urlopen(base_url,context=context)\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    for i in range(1,4):\n",
    "        inc_title.append(soup.select('#tbdyGmScrap > tr:nth-child('+str(i)+') > td.gmtitle > ul > a')[0].get_text())\n",
    "        inc_host.append(soup.select('#tbdyGmScrap > tr:nth-child('+str(i)+') > td.company')[0].get_text().lstrip('\\r\\n\\t\\t\\t\\t\\t\\t\\t').strip('\\r\\n\\t\\t\\t\\t\\t\\t\\t'))\n",
    "        inc_terms.append(soup.select('#tbdyGmScrap > tr:nth-child('+str(i)+') > td.due')[0].get_text())\n",
    "        inc_links.append(soup.select('#tbdyGmScrap > tr:nth-child('+str(i)+') > td.gmtitle > ul > a')[0].get('href'))\n",
    "        \n",
    "    return inc_title, inc_host, inc_terms, inc_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "particular-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incruit_days():\n",
    "    inc_title, inc_host, inc_terms, inc_links=parse_incruit()\n",
    "    inc_start_bef=[]\n",
    "    inc_end_bef=[]\n",
    "    for inc_term in inc_terms:\n",
    "        inc_start_day,inc_end_day=inc_term.split(\"~\")\n",
    "        inc_start_bef.append(inc_start_day.replace('.','-'))\n",
    "        inc_end_bef.append(inc_end_day.replace('.','-'))\n",
    "    return inc_start_bef, inc_end_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "paperback-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_incruit():\n",
    "    inc_title, inc_host, inc_terms, inc_links=parse_incruit()\n",
    "    inc_start_bef, inc_end_bef=incruit_days()\n",
    "    incruit_table_bef = {'type':\"2 공모전\", 'qualification': '대학(원)생','title': inc_title, 'notice': inc_start_bef,  'deadline': inc_end_bef,'dday':0, 'sponsor':inc_host, 'title2': inc_title,'link':inc_links}\n",
    "    df_incruit=pd.DataFrame(incruit_table_bef, columns=['type', 'qualification', 'title', 'notice', 'deadline', 'dday','sponsor', 'title2', 'link'])\n",
    "    return df_incruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "greater-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browser_job():\n",
    "\n",
    "    url ='https://www.jobkorea.co.kr/starter/?chkSubmit=1&schCareer=&schLocal=&schPart=10016&schMajor=&schEduLevel=5&schWork=&schCType=&isSaved=1&LinkGubun=0&LinkNo=0&Page=1&schType=0&schGid=0&schOrderBy=0&schTxt='\n",
    "    browser = Chrome('./chromedriver')\n",
    "    delay=3\n",
    "    browser.implicitly_wait(delay)\n",
    "    browser.get(url) \n",
    "    browser.maximize_window()\n",
    "    page = browser.page_source\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "controlled-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobkorea():\n",
    "    soup = browser_job()\n",
    "    dday = []\n",
    "\n",
    "    links = []\n",
    "    titles = []\n",
    "    insts = []\n",
    "    start_list = [] \n",
    "    end_list = []\n",
    "    element_num = len(soup.select(' .tit > .link > span'))\n",
    "    cnt = int(soup.select(' #TabIngCount')[0].text.replace('(', '').replace(')', '').replace(',', ''))\n",
    "    print(element_num)\n",
    "    print(cnt)\n",
    "    if cnt % element_num == 0:\n",
    "        page_num = cnt / element_num\n",
    "    else :\n",
    "        page_num = int(cnt / element_num) + 1\n",
    "    page_num = int(page_num)\n",
    "    print(page_num)\n",
    "    time.sleep(3)\n",
    "    for k in range(1,page_num+1):\n",
    "        print(k)\n",
    "        url= 'https://www.jobkorea.co.kr/starter/?chkSubmit=1&schCareer=&schLocal=&schPart=10016&schMajor=&schEduLevel=5&schWork=&schCType=&isSaved=1&LinkGubun=0&LinkNo=0&Page=' + str(k) +'&schType=0&schGid=0&schOrderBy=0&schTxt='\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'} \n",
    "        re = requests.get(url, headers=headers)\n",
    "        so = BeautifulSoup(re.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "        length = len(so.select(' .tit > .link '))\n",
    "\n",
    "        for i in range(length):        \n",
    "            base_url = 'http://www.jobkorea.co.kr'\n",
    "            titles.append(soup.select(' .tit > .link > span')[i].text)\n",
    "            insts.append(soup.select(' .coTit > .coLink')[i].text)\n",
    "            links.append(base_url + soup.select(' .tit > a')[i+1]['href'])\n",
    "    for i in range(len(links)):\n",
    "        time.sleep(3)\n",
    "        headers_new = {'User-Agent':'Mozilla/5.0'} \n",
    "        res_new = requests.get(links[i], headers=headers_new)\n",
    "        soup_new = BeautifulSoup(res_new.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "        dday.append(soup_new.select('.devRemainCount > .tahoma')[0].text)\n",
    "\n",
    "        start_list.append(str(parse(soup_new.select(' .date > dd ')[0].text[:10]))[2:10])\n",
    "\n",
    "        end_list.append(str(parse(soup_new.select(' .date > dd ')[1].text[:10]))[2:10])\n",
    "    print(\"crawling_finish\")\n",
    "\n",
    "    tabl_data_bef = {'title': titles, 'notice': start_list, 'deadline': end_list, 'dday':dday, 'sponsor':insts, 'title2':titles, 'link':links}\n",
    "    df = pd.DataFrame(tabl_data_bef, columns=['type','qualification', 'title','notice','deadline','dday','sponsor', 'title2', 'link'])\n",
    "\n",
    "    df['type'] = '5 취업'\n",
    "    df['qualification'] = '대학생'\n",
    "    \n",
    "    print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "illegal-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def browser_job_gra():\n",
    "\n",
    "    url ='https://www.jobkorea.co.kr/starter/?chkSubmit=1&schCareer=&schLocal=&schPart=10016&schMajor=&schEduLevel=6&schWork=&schCType=&isSaved=1&LinkGubun=0&LinkNo=0&Page=1&schType=0&schGid=0&schOrderBy=0&schTxt='\n",
    "    browser = Chrome('./chromedriver')\n",
    "    delay=3\n",
    "    browser.implicitly_wait(delay)\n",
    "    browser.get(url) \n",
    "    browser.maximize_window()\n",
    "    page = browser.page_source\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "furnished-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobkorea_gra():\n",
    "    soup = browser_job_gra()\n",
    "\n",
    "    links = []\n",
    "    titles = []\n",
    "    insts = []\n",
    "    start_list = [] \n",
    "    end_list = []\n",
    "    dday = []\n",
    "    element_num = len(soup.select(' .tit > .link > span'))\n",
    "    cnt = int(soup.select(' #TabIngCount')[0].text.replace('(', '').replace(')', '').replace(',', ''))\n",
    "    print(element_num)\n",
    "    print(cnt)\n",
    "    if cnt % element_num == 0:\n",
    "        page_num = cnt / element_num\n",
    "    else :\n",
    "        page_num = int(cnt / element_num) + 1\n",
    "\n",
    "    page_num = int(page_num)\n",
    "    print(page_num)\n",
    "    time.sleep(3)\n",
    "    for k in range(1,page_num+1):\n",
    "        print(k)\n",
    "        url= 'https://www.jobkorea.co.kr/starter/?chkSubmit=1&schCareer=&schLocal=&schPart=10016&schMajor=&schEduLevel=6&schWork=&schCType=&isSaved=1&LinkGubun=0&LinkNo=0&Page=' + str(k) +'&schType=0&schGid=0&schOrderBy=0&schTxt='\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'} \n",
    "        re = requests.get(url, headers=headers)\n",
    "        so = BeautifulSoup(re.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "        length = len(so.select(' .tit > .link '))\n",
    "\n",
    "        for i in range(length):        \n",
    "            base_url = 'http://www.jobkorea.co.kr'\n",
    "            titles.append(soup.select(' .tit > .link > span')[i].text)\n",
    "            insts.append(soup.select(' .coTit > .coLink')[i].text)\n",
    "            links.append(base_url + soup.select(' .tit > a')[i+1]['href'])\n",
    "    for i in range(len(links)):\n",
    "        time.sleep(3)\n",
    "        headers_new = {'User-Agent':'Mozilla/5.0'} \n",
    "        res_new = requests.get(links[i], headers=headers_new)\n",
    "        soup_new = BeautifulSoup(res_new.content.decode('utf-8', 'replace'), 'html.parser')\n",
    "        dday.append(soup_new.select('.devRemainCount > .tahoma')[0].text)\n",
    "\n",
    "        start_list.append(str(parse(soup_new.select(' .date > dd ')[0].text[:10]))[2:10])\n",
    "\n",
    "        end_list.append(str(parse(soup_new.select(' .date > dd ')[1].text[:10]))[2:10])\n",
    "    \n",
    "    print(\"crawling_finish\")\n",
    "\n",
    "    tabl_data_bef = {'title': titles, 'notice': start_list, 'deadline': end_list, 'dday':dday, 'sponsor':insts, 'title2':titles, 'link':links}\n",
    "    df = pd.DataFrame(tabl_data_bef, columns=['type','qualification', 'title','notice','deadline','dday','sponsor', 'title2', 'link'])\n",
    "\n",
    "    df['type'] = '5 취업'\n",
    "    df['qualification'] = '대학원생'\n",
    "\n",
    "    \n",
    "    print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loose-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_job():\n",
    "    uni = jobkorea()\n",
    "    gra = jobkorea_gra()\n",
    "    job = pd.concat([uni, gra])\n",
    "    job_df = job.reset_index(drop=True)\n",
    "    job_df['title'] = job_df['title'].str.strip()\n",
    "    job_mid = job_df.drop_duplicates(['title'], keep='first')\n",
    "    job_mid2 = job_mid.reset_index(drop = True)\n",
    "    job_mid2['dday'] = job_mid2['dday'].astype(int)\n",
    "    job_fin = job_mid2.sort_values(by ='dday')\n",
    "    final_j = job_fin.reset_index(drop = True)\n",
    "    \n",
    "    return final_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "statistical-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_dreams():\n",
    "    dday_bef = []\n",
    "    page_num = 1\n",
    "    while(page_num <=5):        \n",
    "        url = 'https://www.dreamspon.com/scholarship/scholarship02.html?page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        days = soup.select(\" .td_day > .count\")        \n",
    "        for i in range(len(days)):\n",
    "            if 'D+' in str(days[i].text):\n",
    "                pass\n",
    "            else:\n",
    "                \n",
    "                dday_bef.append((days[i].text).strip(\"D-\"))\n",
    "        page_num += 1  \n",
    "    return dday_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inside-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_test_dreams():\n",
    "    link_test = []\n",
    "    page_num = 1\n",
    "    while(page_num <=5):        \n",
    "        url = 'https://www.dreamspon.com/scholarship/scholarship02.html?page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        contests = soup.find_all(\"p\",class_=\"title\")\n",
    "        days = soup.select(\" .td_day > .count\")        \n",
    "        for i in range(len(days)):\n",
    "            if 'D+' in str(days[i].text):\n",
    "                pass\n",
    "            else:\n",
    "                link_test.append(str(contests[i]).strip('[<p class=\"title\"><a href=\"').strip('</a>'))\n",
    "        page_num += 1  \n",
    "    return link_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "personalized-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_dreams(link_test):\n",
    "    link_bef=[]\n",
    "    page_num = 1\n",
    "    for t in range(len(link_test)):\n",
    "        link_address, title_name = link_test[t].split('\">')\n",
    "        link_ver1 = \"https://www.dreamspon.com/\" + link_address\n",
    "        link_bef.append(link_ver1)\n",
    "    page_num += 1  \n",
    "    return link_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "administrative-solomon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles_dreams(link_test):\n",
    "    titles_bef = [] # 행사 이름\n",
    "    page_num = 1\n",
    "    for t in range(len(link_test)):\n",
    "        link_address, title_name = link_test[t].split('\">')\n",
    "        titles_bef.append(title_name)\n",
    "    page_num += 1  \n",
    "    return titles_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "flush-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insts_dreams():\n",
    "    inst = []\n",
    "    page_num = 1\n",
    "    while(page_num <=5):\n",
    "        url = 'https://www.dreamspon.com/scholarship/scholarship02.html?page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        idx = 1\n",
    "        while(idx<=60):\n",
    "            if 'D-' in str(soup.select(\"tr>td\")[idx+1].text):\n",
    "                inst.append(soup.select(\"tr>td\")[idx].text) #       1,5,9, 13\n",
    "            idx += 4    \n",
    "        page_num += 1\n",
    "    return inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "grateful-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_e_test_dreams(list_adress):\n",
    "\n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    driver.implicitly_wait(10)\n",
    "    login_path ='//*[@id=\"loginForm\"]/div[1]/input'\n",
    "\n",
    "    driver.get(list_adress)\n",
    "    result = driver.switch_to_alert()\n",
    "    result.accept()\n",
    "\n",
    "    driver.find_element_by_name('mbr_id').send_keys('rainrain16@hanmail.net')\n",
    "    driver.find_element_by_name('pwd_in').send_keys('rainrain16')\n",
    "    driver.find_element_by_xpath(login_path).click()\n",
    "\n",
    "    sleep(1)\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "    crawl_data = str(soup.find_all(\"li\", class_= \"day\"))\n",
    "\n",
    "    return crawl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "capital-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_e_days_dreams():\n",
    "    crawl=[]\n",
    "    sd_days_list = link_dreams(link_test_dreams())\n",
    "    \n",
    "    for i in range(len(sd_days_list)):\n",
    "        crawl.append(s_e_test_dreams(sd_days_list[i]))\n",
    "    return crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "colonial-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_e_preprocess():\n",
    "    s_e_pre = s_e_days_dreams()\n",
    "    \n",
    "    for i in range(len(s_e_pre)):\n",
    "        s_e_pre[i] = (s_e_pre[i].strip('[<li class=\"day\" style=\"height: 70px; \">')).strip('\\n\\t')\n",
    "\n",
    "    return s_e_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "technological-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_e_final():\n",
    "    s_e_pre = s_e_preprocess()\n",
    "    start_bef = []\n",
    "    end_bef = []\n",
    "    for i in range(len(s_e_pre)):\n",
    "        if '(1차)' not in s_e_pre[i]:\n",
    "            start_day, end_day_ver1  = (s_e_pre[i]).split('~')\n",
    "            end_day_ver2, end_day_ver3 =  (end_day_ver1).split(\"<span>D\")\n",
    "            start_bef.append(start_day.strip('.'))\n",
    "            end_bef.append(end_day_ver2.strip('.'))\n",
    "\n",
    "        else:            \n",
    "            start_ver1, start_ver2 = (s_e_pre[i]).split('</span><br/>')\n",
    "            start_ver3, end_ver1 = start_ver1.split('~')\n",
    "            end_ver2, end_ver3 = end_ver1.split('<span')\n",
    "\n",
    "            start_ver4 ,end_ver4  = start_ver2.split('~')\n",
    "\n",
    "            \n",
    "            end_ver5, end_ver6 = end_ver4.split('<span')\n",
    "\n",
    "            \n",
    "            start_bef.append('2' + start_ver4.strip(\"(2차) \").strip(\". \"))\n",
    "            end_bef.append(end_ver5.strip(\".\").strip(\" \"))\n",
    "\n",
    "\n",
    "    return start_bef, end_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becoming-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_dreams():\n",
    "    dday =  days_dreams()\n",
    "    links = link_dreams(link_test_dreams())\n",
    "    title = titles_dreams(link_test_dreams())\n",
    "    start, end = s_e_final()\n",
    "    inst = insts_dreams()\n",
    "    \n",
    "    tabl_data_bef = {'type':'3 장학금', 'qualification': \"대학생\",'title': title, 'notice': start,  'deadline': end, 'dday':dday, 'sponsor':inst, 'title2': title,\n",
    "                     'link':links}\n",
    "    df_bef = pd.DataFrame(tabl_data_bef, columns=['type', 'qualification', 'title', 'notice', 'deadline', 'dday', 'sponsor', 'title2', 'link'])\n",
    "\n",
    "    return df_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "serial-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_ck():\n",
    "    title_bef =[]\n",
    "    days_bef = []\n",
    "    start_bef = []\n",
    "    end_bef = []\n",
    "    conditions = []\n",
    "    inst_bef = []\n",
    "    link_bef = []\n",
    "    page_num = 1\n",
    "    while(page_num<=5):\n",
    "        url = 'https://www.contestkorea.com/sub/list.php?displayrow=12&Txt_sGn=1&Txt_key=all&Txt_word=&Txt_bcode=030210001&Txt_code1%5B0%5D=30&Txt_code1%5B1%5D=76&Txt_aarea=&Txt_area=&Txt_sortkey=a.int_sort&Txt_sortword=desc&Txt_chocode=&Txt_unicode=&page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        titles = soup.find_all(\"span\", class_ = \"txt\")\n",
    "        titles = list(titles)\n",
    "        condition = soup.find_all(\"span\", class_=\"condition\")\n",
    "        condition = list(condition)\n",
    "        days = soup.select(\".date > div\" )\n",
    "        days = list(days)\n",
    "        \n",
    "        inst = soup.select(\".host > .icon_1\" )\n",
    "        inst = list(inst)\n",
    "\n",
    "        for i in range(len(condition)):\n",
    "            days[i] = (str(days[i]).strip('<div>').strip(\">\").strip(\"\\t\"))\n",
    "            condition[i] = (str(condition[i]).strip('<span class=\"condition\">').strip(\"</span>\"))\n",
    "            if condition[i] != '접수종료':\n",
    "                conditions.append((condition[i]))\n",
    "                titles[i] = (str(titles[i]).strip('<span class=\"txt\">').strip(\"</'\").strip(\" \"))\n",
    "                days[i] = (str(days[i]).strip('<div>').strip('\\n\\t').strip('</li>'))\n",
    "                inst[i] = (str(inst[i]).strip('<li class=\"icon_1\"><strong>주최</strong> . ').strip('<div>'))\n",
    "                if '공모전' not in titles[i]:\n",
    "                    title_bef.append(titles[i])\n",
    "                    start_day,end_day = days[i].split('~')\n",
    "                    start_bef.append(start_day.replace(\".\", \". \"))\n",
    "                    end_bef.append(end_day.replace(\".\", \". \").strip('\\t'))\n",
    "                    inst_bef.append(inst[i])             \n",
    "        page_num+=1\n",
    "    return title_bef, start_bef, end_bef, inst_bef        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "civilian-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_ck():\n",
    "    conditions=[]\n",
    "    link_bef = []\n",
    "    page_num = 1\n",
    "    while(page_num<=5):\n",
    "        url = 'https://www.contestkorea.com/sub/list.php?displayrow=12&Txt_sGn=1&Txt_key=all&Txt_word=&Txt_bcode=030210001&Txt_code1%5B0%5D=30&Txt_code1%5B1%5D=76&Txt_aarea=&Txt_area=&Txt_sortkey=a.int_sort&Txt_sortword=desc&Txt_chocode=&Txt_unicode=&page=' + str(page_num)\n",
    "        req = urllib.request.urlopen(url)\n",
    "        res = req.read()\n",
    "        soup = BeautifulSoup(res,'html.parser')\n",
    "        titles = soup.find_all(\"span\", class_ = \"txt\")\n",
    "        titles = list(titles)\n",
    "        condition = soup.find_all(\"span\", class_=\"condition\")\n",
    "        condition = list(condition)\n",
    "        for i in range(len(condition)):\n",
    "            condition[i] = (str(condition[i]).strip('<span class=\"condition\">').strip(\"</span>\"))\n",
    "            if condition[i] != '접수종료':\n",
    "                conditions.append((condition[i]))\n",
    "                titles[i] = (str(titles[i]).strip('<span class=\"txt\">').strip(\"</'\").strip(\" \"))\n",
    "                if '공모전' not in titles[i]:                 \n",
    "                    browser = Chrome('./chromedriver')\n",
    "                    delay=1\n",
    "                    browser.implicitly_wait(delay)\n",
    "                    browser.get(url)\n",
    "                    browser.maximize_window()\n",
    "                    link_adress = '//*[@id=\"frm\"]/div/div[4]/ul/li['+ str(i+1) + ']/div[1]/a'\n",
    "                    browser.find_elements_by_xpath(link_adress)[0].click()\n",
    "                    sleep(0.5)\n",
    "                    link_bef.append(browser.current_url)\n",
    "                    \n",
    "                    \n",
    "        page_num+=1\n",
    "    return link_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "variable-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling_ck():\n",
    "    title_bef, start_bef, end_bef, inst_bef = base_ck()\n",
    "    link_bef = link_ck()\n",
    "    \n",
    "    tabl_data_bef = {'type':\"1 경진대회\", 'qualification': \"대학(원)생\",'title':  title_bef, 'notice': start_bef,  'deadline': end_bef, 'dday':0,'sponsor':inst_bef, 'title2': title_bef,\n",
    "                     'link':link_bef}\n",
    "\n",
    "    df_bef = pd.DataFrame(tabl_data_bef, columns=['type', 'qualification', 'title', 'notice', 'deadline', 'dday', 'sponsor', 'title2', 'link'])\n",
    "    return df_bef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "imported-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contest():\n",
    "    you = crawling()\n",
    "    good = browser2()\n",
    "    incruit=final_incruit()\n",
    "    contest = pd.concat([you, good, incruit])\n",
    "    contest_df = contest.reset_index(drop=True)\n",
    "    contest_df['title'] = contest_df['title'].str.strip()\n",
    "    contest_mid = contest_df.drop_duplicates(['title'], keep='first')\n",
    "    contest_mid2 = contest_mid.reset_index(drop = True)\n",
    "    contest_mid2['dday'] = contest_mid2['dday'].astype(int)\n",
    "    contest_fin = contest_mid2.sort_values(by ='dday')\n",
    "    final = contest_fin.reset_index(drop = True)\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "psychological-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum():\n",
    "    df1 = crawling_ck() #1 경진대회\n",
    "    df2 = sort_contest() # 2 공모전\n",
    "    df3 =  final_dreams() # 3 장학금\n",
    "    df4 = final_allcon() # 4 대외활동\n",
    "    df5 = sort_job() # 5 취업\n",
    "    mid = pd.concat([df1, df2, df3, df4, df5]) \n",
    "    mid_df = mid.reset_index(drop=True)\n",
    "    mid_df['title'] = mid_df['title'].str.strip()\n",
    "    fin_df = mid_df.drop_duplicates(['title'], keep='first')\n",
    "    fin = fin_df.reset_index(drop = True)\n",
    "    fin['dday'] = '0'\n",
    "    print(fin)\n",
    "\n",
    "    return fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "premier-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국소프트웨어산업협회', '산업통상자원부', '(주)엔티렉스-디바이스마트']\n",
      "{'title': ['2021 SW 챌린지 창업 공모전 (~4/2 마감) ', '제9회 엔지니어링산업설계대전 ', '2021 ICT 융합 프로젝트 공모전 '], 'notice': ['21-02-18', '21-02-01', '21-02-01'], 'deadline': ['21-04-02', '21-03-19', '21-03-31'], 'dday': ['41', '27', '39'], 'sponsor': ['한국소프트웨어산업협회', '산업통상자원부', '(주)엔티렉스-디바이스마트'], 'title2': ['2021 SW 챌린지 창업 공모전 (~4/2 마감) ', '제9회 엔지니어링산업설계대전 ', '2021 ICT 융합 프로젝트 공모전 '], 'link': ['https://thinkyou.co.kr/contest/sector_view.asp?idx=17023&page=1&pagesize=30&serstatus=&serdivision=&serfield=5&sertarget=0&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16808&page=1&pagesize=30&serstatus=&serdivision=&serfield=5&sertarget=0&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16631&page=1&pagesize=30&serstatus=&serdivision=&serfield=5&sertarget=0&serprizeMoney=&seritem=0&searchstr=']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjayh\\anaconda3\\envs\\crawling\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: use driver.switch_to.alert instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "172\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "crawling_finish\n",
      "     type qualification                           title    notice  deadline  \\\n",
      "0    5 취업           대학생        21년 상반기 보안관제 채용연계형 인턴 모집  21-02-15  21-02-21   \n",
      "1    5 취업           대학생            미디어로그 Java 개발 경력자 모집  21-02-19  21-03-05   \n",
      "2    5 취업           대학생                 콘텐츠 마케팅 경력사원 채용  21-02-18  21-03-01   \n",
      "3    5 취업           대학생           CJ프레시웨이 데이터분석 경력사원 모집  21-02-19  21-03-04   \n",
      "4    5 취업           대학생               [한국자산평가] 인턴 채용 공고  21-02-20  21-03-01   \n",
      "..    ...           ...                             ...       ...       ...   \n",
      "167  5 취업           대학생  Field Service Engineer 신입사원 모집  21-02-18  21-02-21   \n",
      "168  5 취업           대학생   [교원그룹] e커머스지원팀 경력직 수시채용(웹 개발)  21-02-18  21-03-03   \n",
      "169  5 취업           대학생  [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용  21-02-18  21-04-19   \n",
      "170  5 취업           대학생            2021년 2월 한미정밀화학 인재채용  21-02-19  21-02-21   \n",
      "171  5 취업           대학생                디지털AI전략팀 경력직원 채용  21-02-18  21-03-01   \n",
      "\n",
      "    dday    sponsor                          title2  \\\n",
      "0      1        ㈜윈스        21년 상반기 보안관제 채용연계형 인턴 모집   \n",
      "1     13     ㈜미디어로그            미디어로그 Java 개발 경력자 모집   \n",
      "2      9       ㈜펫츠비                 콘텐츠 마케팅 경력사원 채용   \n",
      "3     12   씨제이프레시웨이           CJ프레시웨이 데이터분석 경력사원 모집   \n",
      "4      9    한국자산평가㈜               [한국자산평가] 인턴 채용 공고   \n",
      "..   ...        ...                             ...   \n",
      "167    1    델인터내셔널㈜  Field Service Engineer 신입사원 모집   \n",
      "168   11       교원그룹   [교원그룹] e커머스지원팀 경력직 수시채용(웹 개발)   \n",
      "169   58     ㈜투비소프트  [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
      "170    1    한미정밀화학㈜            2021년 2월 한미정밀화학 인재채용   \n",
      "171    9  미래에셋자산운용㈜                디지털AI전략팀 경력직원 채용   \n",
      "\n",
      "                                                  link  \n",
      "0    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "1    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "2    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "3    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "4    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "..                                                 ...  \n",
      "167  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "168  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "169  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "170  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "171  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "\n",
      "[172 rows x 9 columns]\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "crawling_finish\n",
      "   type qualification                                 title    notice  \\\n",
      "0  5 취업          대학원생               [전문연구요원] 빅데이터 엔지니어 수시채용  21-02-18   \n",
      "1  5 취업          대학원생  2021년도 제1차 전문경력직(연구ㆍ전문ㆍ경력신입) 선발 모집요강  21-02-10   \n",
      "2  5 취업          대학원생            [NHN] 2021년 (신입) 전문연구요원 모집  21-01-15   \n",
      "3  5 취업          대학원생      머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용  20-12-28   \n",
      "\n",
      "   deadline dday     sponsor                                title2  \\\n",
      "0  21-03-10   18         ㈜웹젠               [전문연구요원] 빅데이터 엔지니어 수시채용   \n",
      "1  21-02-25    4    한국수력원자력㈜  2021년도 제1차 전문경력직(연구ㆍ전문ㆍ경력신입) 선발 모집요강   \n",
      "2  21-04-15   54  엔에이치엔 주식회사            [NHN] 2021년 (신입) 전문연구요원 모집   \n",
      "3  21-03-28   36        ㈜씨이랩      머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
      "\n",
      "                                                link  \n",
      "0  http://www.jobkorea.co.kr/Recruit/GI_Read/3393...  \n",
      "1  http://www.jobkorea.co.kr/Recruit/GI_Read/3387...  \n",
      "2  http://www.jobkorea.co.kr/Recruit/GI_Read/3366...  \n",
      "3  http://www.jobkorea.co.kr/Recruit/GI_Read/3352...  \n",
      "       type qualification                                       title  \\\n",
      "0    1 경진대회        대학(원)생                          스타트업과 함께하는 피버팅 해커톤   \n",
      "1    1 경진대회        대학(원)생                             2021 다솜이 드림메이커스   \n",
      "2     2 공모전        대학(원)생                         제38회 기상기후 사진·영상 공모전   \n",
      "3     2 공모전        대학(원)생                                   슬기로운 과학생활   \n",
      "4     2 공모전        대학(원)생                             2021 의료기기 창업공모전   \n",
      "..      ...           ...                                         ...   \n",
      "165    5 취업          대학원생            머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
      "166    5 취업          대학원생                  [NHN] 2021년 (신입) 전문연구요원 모집   \n",
      "167    5 취업           대학생              [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
      "168    5 취업           대학생                     온라인 미디어서비스 운영및 기술지원자 모집   \n",
      "169    5 취업           대학생  [효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집   \n",
      "\n",
      "         notice    deadline dday              sponsor  \\\n",
      "0    21. 02. 26  21. 03. 08    0               한국무역협회   \n",
      "1    21. 01. 13  21. 12. 31    0     생명보험사회공헌재단, 교보생명   \n",
      "2      21-01-28    21-02-25    0                  기상청   \n",
      "3      20-09-21    21-10-04    0              국립중앙과학관   \n",
      "4    2021-02-23  2021-03-23    0  강원도, 원주시, 한국보건산업진흥원   \n",
      "..          ...         ...  ...                  ...   \n",
      "165    20-12-28    21-03-28    0                 ㈜씨이랩   \n",
      "166    21-01-15    21-04-15    0           엔에이치엔 주식회사   \n",
      "167    21-02-18    21-04-19    0               ㈜투비소프트   \n",
      "168    21-02-17    21-05-18    0              ㈜씨디네트웍스   \n",
      "169    21-02-18    21-05-19    0               효성ITX㈜   \n",
      "\n",
      "                                         title2  \\\n",
      "0                            스타트업과 함께하는 피버팅 해커톤   \n",
      "1                               2021 다솜이 드림메이커스   \n",
      "2                           제38회 기상기후 사진·영상 공모전   \n",
      "3                                     슬기로운 과학생활   \n",
      "4                               2021 의료기기 창업공모전   \n",
      "..                                          ...   \n",
      "165            머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
      "166                  [NHN] 2021년 (신입) 전문연구요원 모집   \n",
      "167              [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
      "168                     온라인 미디어서비스 운영및 기술지원자 모집   \n",
      "169  [효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집   \n",
      "\n",
      "                                                  link  \n",
      "0    https://www.contestkorea.com/sub/view.php?disp...  \n",
      "1    https://www.contestkorea.com/sub/view.php?disp...  \n",
      "2    https://gongmo.incruit.com/info/gongmolistinfo...  \n",
      "3    https://gongmo.incruit.com/info/gongmolistinfo...  \n",
      "4    https://www.thinkcontest.com//Contest/ContestD...  \n",
      "..                                                 ...  \n",
      "165  http://www.jobkorea.co.kr/Recruit/GI_Read/3352...  \n",
      "166  http://www.jobkorea.co.kr/Recruit/GI_Read/3366...  \n",
      "167  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "168  http://www.jobkorea.co.kr/Recruit/GI_Read/3393...  \n",
      "169  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "\n",
      "[170 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>qualification</th>\n",
       "      <th>title</th>\n",
       "      <th>notice</th>\n",
       "      <th>deadline</th>\n",
       "      <th>dday</th>\n",
       "      <th>sponsor</th>\n",
       "      <th>title2</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 경진대회</td>\n",
       "      <td>대학(원)생</td>\n",
       "      <td>스타트업과 함께하는 피버팅 해커톤</td>\n",
       "      <td>21. 02. 26</td>\n",
       "      <td>21. 03. 08</td>\n",
       "      <td>0</td>\n",
       "      <td>한국무역협회</td>\n",
       "      <td>스타트업과 함께하는 피버팅 해커톤</td>\n",
       "      <td>https://www.contestkorea.com/sub/view.php?disp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 경진대회</td>\n",
       "      <td>대학(원)생</td>\n",
       "      <td>2021 다솜이 드림메이커스</td>\n",
       "      <td>21. 01. 13</td>\n",
       "      <td>21. 12. 31</td>\n",
       "      <td>0</td>\n",
       "      <td>생명보험사회공헌재단, 교보생명</td>\n",
       "      <td>2021 다솜이 드림메이커스</td>\n",
       "      <td>https://www.contestkorea.com/sub/view.php?disp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 공모전</td>\n",
       "      <td>대학(원)생</td>\n",
       "      <td>제38회 기상기후 사진·영상 공모전</td>\n",
       "      <td>21-01-28</td>\n",
       "      <td>21-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>기상청</td>\n",
       "      <td>제38회 기상기후 사진·영상 공모전</td>\n",
       "      <td>https://gongmo.incruit.com/info/gongmolistinfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 공모전</td>\n",
       "      <td>대학(원)생</td>\n",
       "      <td>슬기로운 과학생활</td>\n",
       "      <td>20-09-21</td>\n",
       "      <td>21-10-04</td>\n",
       "      <td>0</td>\n",
       "      <td>국립중앙과학관</td>\n",
       "      <td>슬기로운 과학생활</td>\n",
       "      <td>https://gongmo.incruit.com/info/gongmolistinfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 공모전</td>\n",
       "      <td>대학(원)생</td>\n",
       "      <td>2021 의료기기 창업공모전</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>0</td>\n",
       "      <td>강원도, 원주시, 한국보건산업진흥원</td>\n",
       "      <td>2021 의료기기 창업공모전</td>\n",
       "      <td>https://www.thinkcontest.com//Contest/ContestD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>5 취업</td>\n",
       "      <td>대학원생</td>\n",
       "      <td>머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용</td>\n",
       "      <td>20-12-28</td>\n",
       "      <td>21-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>㈜씨이랩</td>\n",
       "      <td>머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용</td>\n",
       "      <td>http://www.jobkorea.co.kr/Recruit/GI_Read/3352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>5 취업</td>\n",
       "      <td>대학원생</td>\n",
       "      <td>[NHN] 2021년 (신입) 전문연구요원 모집</td>\n",
       "      <td>21-01-15</td>\n",
       "      <td>21-04-15</td>\n",
       "      <td>0</td>\n",
       "      <td>엔에이치엔 주식회사</td>\n",
       "      <td>[NHN] 2021년 (신입) 전문연구요원 모집</td>\n",
       "      <td>http://www.jobkorea.co.kr/Recruit/GI_Read/3366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>5 취업</td>\n",
       "      <td>대학생</td>\n",
       "      <td>[㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용</td>\n",
       "      <td>21-02-18</td>\n",
       "      <td>21-04-19</td>\n",
       "      <td>0</td>\n",
       "      <td>㈜투비소프트</td>\n",
       "      <td>[㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용</td>\n",
       "      <td>http://www.jobkorea.co.kr/Recruit/GI_Read/3394...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>5 취업</td>\n",
       "      <td>대학생</td>\n",
       "      <td>온라인 미디어서비스 운영및 기술지원자 모집</td>\n",
       "      <td>21-02-17</td>\n",
       "      <td>21-05-18</td>\n",
       "      <td>0</td>\n",
       "      <td>㈜씨디네트웍스</td>\n",
       "      <td>온라인 미디어서비스 운영및 기술지원자 모집</td>\n",
       "      <td>http://www.jobkorea.co.kr/Recruit/GI_Read/3393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>5 취업</td>\n",
       "      <td>대학생</td>\n",
       "      <td>[효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집</td>\n",
       "      <td>21-02-18</td>\n",
       "      <td>21-05-19</td>\n",
       "      <td>0</td>\n",
       "      <td>효성ITX㈜</td>\n",
       "      <td>[효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집</td>\n",
       "      <td>http://www.jobkorea.co.kr/Recruit/GI_Read/3394...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type qualification                                       title  \\\n",
       "0    1 경진대회        대학(원)생                          스타트업과 함께하는 피버팅 해커톤   \n",
       "1    1 경진대회        대학(원)생                             2021 다솜이 드림메이커스   \n",
       "2     2 공모전        대학(원)생                         제38회 기상기후 사진·영상 공모전   \n",
       "3     2 공모전        대학(원)생                                   슬기로운 과학생활   \n",
       "4     2 공모전        대학(원)생                             2021 의료기기 창업공모전   \n",
       "..      ...           ...                                         ...   \n",
       "165    5 취업          대학원생            머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
       "166    5 취업          대학원생                  [NHN] 2021년 (신입) 전문연구요원 모집   \n",
       "167    5 취업           대학생              [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
       "168    5 취업           대학생                     온라인 미디어서비스 운영및 기술지원자 모집   \n",
       "169    5 취업           대학생  [효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집   \n",
       "\n",
       "         notice    deadline dday              sponsor  \\\n",
       "0    21. 02. 26  21. 03. 08    0               한국무역협회   \n",
       "1    21. 01. 13  21. 12. 31    0     생명보험사회공헌재단, 교보생명   \n",
       "2      21-01-28    21-02-25    0                  기상청   \n",
       "3      20-09-21    21-10-04    0              국립중앙과학관   \n",
       "4    2021-02-23  2021-03-23    0  강원도, 원주시, 한국보건산업진흥원   \n",
       "..          ...         ...  ...                  ...   \n",
       "165    20-12-28    21-03-28    0                 ㈜씨이랩   \n",
       "166    21-01-15    21-04-15    0           엔에이치엔 주식회사   \n",
       "167    21-02-18    21-04-19    0               ㈜투비소프트   \n",
       "168    21-02-17    21-05-18    0              ㈜씨디네트웍스   \n",
       "169    21-02-18    21-05-19    0               효성ITX㈜   \n",
       "\n",
       "                                         title2  \\\n",
       "0                            스타트업과 함께하는 피버팅 해커톤   \n",
       "1                               2021 다솜이 드림메이커스   \n",
       "2                           제38회 기상기후 사진·영상 공모전   \n",
       "3                                     슬기로운 과학생활   \n",
       "4                               2021 의료기기 창업공모전   \n",
       "..                                          ...   \n",
       "165            머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
       "166                  [NHN] 2021년 (신입) 전문연구요원 모집   \n",
       "167              [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
       "168                     온라인 미디어서비스 운영및 기술지원자 모집   \n",
       "169  [효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집   \n",
       "\n",
       "                                                  link  \n",
       "0    https://www.contestkorea.com/sub/view.php?disp...  \n",
       "1    https://www.contestkorea.com/sub/view.php?disp...  \n",
       "2    https://gongmo.incruit.com/info/gongmolistinfo...  \n",
       "3    https://gongmo.incruit.com/info/gongmolistinfo...  \n",
       "4    https://www.thinkcontest.com//Contest/ContestD...  \n",
       "..                                                 ...  \n",
       "165  http://www.jobkorea.co.kr/Recruit/GI_Read/3352...  \n",
       "166  http://www.jobkorea.co.kr/Recruit/GI_Read/3366...  \n",
       "167  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
       "168  http://www.jobkorea.co.kr/Recruit/GI_Read/3393...  \n",
       "169  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
       "\n",
       "[170 rows x 9 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "convertible-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tofb():\n",
    "    fin = sum()\n",
    "\n",
    "\n",
    "    postdata = fin.to_dict(orient=\"index\")\n",
    "    config = {\n",
    "        \"apiKey\": \"AIzaSyDIo8bt7OrCX6KYaxplvUauQdaehcjUo_0\",\n",
    "        \"authDomain\": \"activity-crawling.firebaseapp.com\",\n",
    "        \"databaseURL\": \"https://activity-crawling-default-rtdb.firebaseio.com\",\n",
    "        \"projectId\": \"activity-crawling\",\n",
    "        \"storageBucket\": \"activity-crawling.appspot.com\",\n",
    "        \"messagingSenderId\": \"608978503357\",\n",
    "        \"appId\": \"1:608978503357:web:374a269b8fa1a64888d9d4\"}\n",
    "    firebase = pyrebase.initialize_app(config)\n",
    "    db = firebase.database()\n",
    "    db.remove()\n",
    "    db.child().update(postdata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "julian-surface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한국국제교류재단', '한국산업인력공단, ETS Korea, YBM', '울산광역시 남구 관광과', '서울대학교병원', '고용노동부', 'IBK 기업은행', '(주)LF', '에버랜드', '세종시, 한국토지주택공사', '국토교통부', '열매나눔인터내셔널', '외교부', '국립외교원', '주)메세코리아', '서울시립대학교 도시인문학연구소', '식품의약품안전처', 'blabla', '서초구립반포도서관', '서초구립반포도서관', '한국소프트웨어산업협회']\n",
      "{'title': ['2021 KF국민공공외교 프로젝트 공모 ', '월드잡플러스 X 토익스피킹 영어 말하기 대회 ', '울산 관광 유튜브 공모전(Feel the crazy of Ulsan) ', '서울대학교병원 대한외래 멀티-시네마월 영상작품 공모전 ', '2021년 제30회 장애인고용 콘텐츠 공모전 ', 'IBK기업은행 주최 중소기업 학술 컨퍼런스 연구지원 논문 공모전 ', '챔피온 서포터즈 1기 모집 ', '에버랜드 선생님 트렌드 서포터즈 모집 ', '2021 스마트시티 60초 영화제 공모전 ', '2021년도 부동산서비스산업 창업경진대회 ', 'MYI 공식 서포터즈 메리커스 1기 모집 ', 'KOREAZ 명예기자단 모집 ', '국립외교원 제1기 국민외교아카데미 서포터즈 모집 ', '2021 부산국제식품박람회 서포터즈 모집 ', '2021 제 2회 서울시립대학교 도시인문학연구소 영화 평론상 ', '불량식품 근절을 위한 캘리그라피 공모전 ', '전국 대학생 추천 노래자랑 ', '서초구립반포도서관 도서추천 크리에이터 [북포유]-2기 모집 (재능기부자 모집) ', '서초구립반포도서관 대학생 홍보 서포터즈-2기 모집 (재능기부자 모집) ', '2021 SW 챌린지 창업 공모전 (~4/2 마감) '], 'notice': ['21-02-19', '21-02-08', '21-02-22', '21-02-08', '21-02-01', '21-01-15', '21-02-19', '21-02-15', '21-02-22', '21-02-22', '21-02-17', '21-02-10', '21-02-09', '21-02-18', '21-02-18', '21-02-22', '21-02-17', '21-02-14', '21-02-14', '21-02-18'], 'deadline': ['21-03-19', '21-03-07', '21-03-31', '21-04-30', '21-03-14', '21-02-28', '21-02-28', '21-02-28', '21-03-26', '21-05-03', '21-03-01', '21-02-24', '21-02-22', '21-02-21', '21-04-30', '21-04-23', '21-03-14', '21-02-22', '21-02-22', '21-04-02'], 'dday': ['27', '15', '2', '69', '22', '8', '8', '8', '2', '2', '9', '4', '2', '1', '69', '2', '22', '2', '2', '41'], 'sponsor': ['한국국제교류재단', '한국산업인력공단, ETS Korea, YBM', '울산광역시 남구 관광과', '서울대학교병원', '고용노동부', 'IBK 기업은행', '(주)LF', '에버랜드', '세종시, 한국토지주택공사', '국토교통부', '열매나눔인터내셔널', '외교부', '국립외교원', '주)메세코리아', '서울시립대학교 도시인문학연구소', '식품의약품안전처', 'blabla', '서초구립반포도서관', '서초구립반포도서관', '한국소프트웨어산업협회'], 'title2': ['2021 KF국민공공외교 프로젝트 공모 ', '월드잡플러스 X 토익스피킹 영어 말하기 대회 ', '울산 관광 유튜브 공모전(Feel the crazy of Ulsan) ', '서울대학교병원 대한외래 멀티-시네마월 영상작품 공모전 ', '2021년 제30회 장애인고용 콘텐츠 공모전 ', 'IBK기업은행 주최 중소기업 학술 컨퍼런스 연구지원 논문 공모전 ', '챔피온 서포터즈 1기 모집 ', '에버랜드 선생님 트렌드 서포터즈 모집 ', '2021 스마트시티 60초 영화제 공모전 ', '2021년도 부동산서비스산업 창업경진대회 ', 'MYI 공식 서포터즈 메리커스 1기 모집 ', 'KOREAZ 명예기자단 모집 ', '국립외교원 제1기 국민외교아카데미 서포터즈 모집 ', '2021 부산국제식품박람회 서포터즈 모집 ', '2021 제 2회 서울시립대학교 도시인문학연구소 영화 평론상 ', '불량식품 근절을 위한 캘리그라피 공모전 ', '전국 대학생 추천 노래자랑 ', '서초구립반포도서관 도서추천 크리에이터 [북포유]-2기 모집 (재능기부자 모집) ', '서초구립반포도서관 대학생 홍보 서포터즈-2기 모집 (재능기부자 모집) ', '2021 SW 챌린지 창업 공모전 (~4/2 마감) '], 'link': ['https://thinkyou.co.kr/contest/sector_view.asp?idx=17017&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16894&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16939&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16842&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16798&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16618&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17045&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17042&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17040&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17039&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17037&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17036&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17035&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17034&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17032&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17031&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17030&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16987&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=16986&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=', 'https://thinkyou.co.kr/contest/sector_view.asp?idx=17023&page=1&pagesize=30&serstatus=&serdivision=&serfield=&sertarget=&serprizeMoney=&seritem=0&searchstr=']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjayh\\anaconda3\\envs\\crawling\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: use driver.switch_to.alert instead\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "172\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "crawling_finish\n",
      "     type qualification                           title    notice  deadline  \\\n",
      "0    5 취업           대학생        21년 상반기 보안관제 채용연계형 인턴 모집  21-02-15  21-02-21   \n",
      "1    5 취업           대학생            미디어로그 Java 개발 경력자 모집  21-02-19  21-03-05   \n",
      "2    5 취업           대학생                 콘텐츠 마케팅 경력사원 채용  21-02-18  21-03-01   \n",
      "3    5 취업           대학생           CJ프레시웨이 데이터분석 경력사원 모집  21-02-19  21-03-04   \n",
      "4    5 취업           대학생               [한국자산평가] 인턴 채용 공고  21-02-20  21-03-01   \n",
      "..    ...           ...                             ...       ...       ...   \n",
      "167  5 취업           대학생  Field Service Engineer 신입사원 모집  21-02-18  21-02-21   \n",
      "168  5 취업           대학생   [교원그룹] e커머스지원팀 경력직 수시채용(웹 개발)  21-02-18  21-03-03   \n",
      "169  5 취업           대학생  [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용  21-02-18  21-04-19   \n",
      "170  5 취업           대학생            2021년 2월 한미정밀화학 인재채용  21-02-19  21-02-21   \n",
      "171  5 취업           대학생                디지털AI전략팀 경력직원 채용  21-02-18  21-03-01   \n",
      "\n",
      "    dday    sponsor                          title2  \\\n",
      "0      1        ㈜윈스        21년 상반기 보안관제 채용연계형 인턴 모집   \n",
      "1     13     ㈜미디어로그            미디어로그 Java 개발 경력자 모집   \n",
      "2      9       ㈜펫츠비                 콘텐츠 마케팅 경력사원 채용   \n",
      "3     12   씨제이프레시웨이           CJ프레시웨이 데이터분석 경력사원 모집   \n",
      "4      9    한국자산평가㈜               [한국자산평가] 인턴 채용 공고   \n",
      "..   ...        ...                             ...   \n",
      "167    1    델인터내셔널㈜  Field Service Engineer 신입사원 모집   \n",
      "168   10       교원그룹   [교원그룹] e커머스지원팀 경력직 수시채용(웹 개발)   \n",
      "169   58     ㈜투비소프트  [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
      "170    1    한미정밀화학㈜            2021년 2월 한미정밀화학 인재채용   \n",
      "171    9  미래에셋자산운용㈜                디지털AI전략팀 경력직원 채용   \n",
      "\n",
      "                                                  link  \n",
      "0    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "1    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "2    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "3    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "4    http://www.jobkorea.co.kr/Recruit/GI_Read/3395...  \n",
      "..                                                 ...  \n",
      "167  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "168  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "169  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "170  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "171  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "\n",
      "[172 rows x 9 columns]\n",
      "4\n",
      "4\n",
      "1\n",
      "1\n",
      "crawling_finish\n",
      "   type qualification                                 title    notice  \\\n",
      "0  5 취업          대학원생               [전문연구요원] 빅데이터 엔지니어 수시채용  21-02-18   \n",
      "1  5 취업          대학원생  2021년도 제1차 전문경력직(연구ㆍ전문ㆍ경력신입) 선발 모집요강  21-02-10   \n",
      "2  5 취업          대학원생            [NHN] 2021년 (신입) 전문연구요원 모집  21-01-15   \n",
      "3  5 취업          대학원생      머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용  20-12-28   \n",
      "\n",
      "   deadline dday     sponsor                                title2  \\\n",
      "0  21-03-10   18         ㈜웹젠               [전문연구요원] 빅데이터 엔지니어 수시채용   \n",
      "1  21-02-25    4    한국수력원자력㈜  2021년도 제1차 전문경력직(연구ㆍ전문ㆍ경력신입) 선발 모집요강   \n",
      "2  21-04-15   54  엔에이치엔 주식회사            [NHN] 2021년 (신입) 전문연구요원 모집   \n",
      "3  21-03-28   36        ㈜씨이랩      머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
      "\n",
      "                                                link  \n",
      "0  http://www.jobkorea.co.kr/Recruit/GI_Read/3393...  \n",
      "1  http://www.jobkorea.co.kr/Recruit/GI_Read/3387...  \n",
      "2  http://www.jobkorea.co.kr/Recruit/GI_Read/3366...  \n",
      "3  http://www.jobkorea.co.kr/Recruit/GI_Read/3352...  \n",
      "       type qualification                                       title  \\\n",
      "0    1 경진대회        대학(원)생                          스타트업과 함께하는 피버팅 해커톤   \n",
      "1    1 경진대회        대학(원)생                             2021 다솜이 드림메이커스   \n",
      "2     2 공모전        대학(원)생                                   슬기로운 과학생활   \n",
      "3     2 공모전        대학(원)생                         제38회 기상기후 사진·영상 공모전   \n",
      "4     2 공모전        대학(원)생                      2021 부산국제식품박람회 서포터즈 모집   \n",
      "..      ...           ...                                         ...   \n",
      "184    5 취업          대학원생            머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
      "185    5 취업          대학원생                  [NHN] 2021년 (신입) 전문연구요원 모집   \n",
      "186    5 취업           대학생              [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
      "187    5 취업           대학생                     온라인 미디어서비스 운영및 기술지원자 모집   \n",
      "188    5 취업           대학생  [효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집   \n",
      "\n",
      "         notice    deadline dday           sponsor  \\\n",
      "0    21. 02. 26  21. 03. 08    0            한국무역협회   \n",
      "1    21. 01. 13  21. 12. 31    0  생명보험사회공헌재단, 교보생명   \n",
      "2      20-09-21    21-10-04    0           국립중앙과학관   \n",
      "3      21-01-28    21-02-25    0               기상청   \n",
      "4      21-02-18    21-02-21    0           주)메세코리아   \n",
      "..          ...         ...  ...               ...   \n",
      "184    20-12-28    21-03-28    0              ㈜씨이랩   \n",
      "185    21-01-15    21-04-15    0        엔에이치엔 주식회사   \n",
      "186    21-02-18    21-04-19    0            ㈜투비소프트   \n",
      "187    21-02-17    21-05-18    0           ㈜씨디네트웍스   \n",
      "188    21-02-18    21-05-19    0            효성ITX㈜   \n",
      "\n",
      "                                         title2  \\\n",
      "0                            스타트업과 함께하는 피버팅 해커톤   \n",
      "1                               2021 다솜이 드림메이커스   \n",
      "2                                     슬기로운 과학생활   \n",
      "3                           제38회 기상기후 사진·영상 공모전   \n",
      "4                       2021 부산국제식품박람회 서포터즈 모집    \n",
      "..                                          ...   \n",
      "184            머신러닝, 인공지능(AI), 클라우드 연구개발 경력직 채용   \n",
      "185                  [NHN] 2021년 (신입) 전문연구요원 모집   \n",
      "186              [㈜투비소프트] 연구개발본부 각 부문별 경력개발자 채용   \n",
      "187                     온라인 미디어서비스 운영및 기술지원자 모집   \n",
      "188  [효성ITX] 웹  솔루션/시스템 운영 및 응용프로그램 개발자 경력사원 모집   \n",
      "\n",
      "                                                  link  \n",
      "0    https://www.contestkorea.com/sub/view.php?disp...  \n",
      "1    https://www.contestkorea.com/sub/view.php?disp...  \n",
      "2    https://gongmo.incruit.com/info/gongmolistinfo...  \n",
      "3    https://gongmo.incruit.com/info/gongmolistinfo...  \n",
      "4    https://thinkyou.co.kr/contest/sector_view.asp...  \n",
      "..                                                 ...  \n",
      "184  http://www.jobkorea.co.kr/Recruit/GI_Read/3352...  \n",
      "185  http://www.jobkorea.co.kr/Recruit/GI_Read/3366...  \n",
      "186  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "187  http://www.jobkorea.co.kr/Recruit/GI_Read/3393...  \n",
      "188  http://www.jobkorea.co.kr/Recruit/GI_Read/3394...  \n",
      "\n",
      "[189 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "tofb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job():\n",
    "    now = datetime.now()\n",
    "    print(now)\n",
    "    tofb()\n",
    "    print(\"end\")\n",
    "\n",
    "\n",
    "schedule.every().day.at(\"00:00\").do(job)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-illness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling",
   "language": "python",
   "name": "crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
